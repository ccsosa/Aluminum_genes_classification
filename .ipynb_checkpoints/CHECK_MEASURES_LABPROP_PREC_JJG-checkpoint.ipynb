{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32bf9470",
   "metadata": {},
   "source": [
    "# LOADING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a808951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "import pandas as pd\n",
    "#import networkx as nx\n",
    "#import csv\n",
    "#from sys import stdin\n",
    "#from networkx.algorithms.community import greedy_modularity_communities\n",
    "#from networkx.algorithms.community import k_clique_communities\n",
    "#from networkx.algorithms.community import asyn_lpa_communities\n",
    "#from networkx.algorithms.community import modularity\n",
    "#from cdlib import algorithms, readwrite, viz\n",
    "#from sklearn.manifold import TSNE\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import LogisticRegressionCV\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from gensim.models import Word2Vec\n",
    "from sklearn import preprocessing\n",
    "import sklearn.metrics as sk_metrics\n",
    "#import seaborn as sns\n",
    "\n",
    "#################\n",
    "def fixed_metrics(y,y_pred):\n",
    "    from sklearn import metrics\n",
    "    import pandas as pd\n",
    "    import sklearn.metrics as sk_metrics\n",
    "    \n",
    "\n",
    "    cm = sk_metrics.confusion_matrix(y, y_pred)\n",
    "\n",
    "    results_partial = y.copy()\n",
    "    results_partial=pd.DataFrame(results_partial)\n",
    "    results_partial[\"pred\"] = y_pred\n",
    "    results_partial = results_partial[(results_partial.iloc[:,0]<1)]\n",
    "    \n",
    "    alfa = sum(results_partial[\"pred\"])/results_partial.shape[0]\n",
    "    beta = 1\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, y_pred, pos_label=1)\n",
    "\n",
    "    \n",
    "    TN = cm[0,0]\n",
    "    FN = cm[1,0]\n",
    "    TP = cm[1,1]\n",
    "    FP = cm[0,1]\n",
    "    \n",
    "    theta = (TP+FP)/(TP+FN+TN+FP)\n",
    "    n=FP/(TN+FP)\n",
    "    #pi = (TP+FN)/(TP+FN+TN+FP)\n",
    "    c= len(y[(y.iloc[:,0]==1)])/(len(y[(y.iloc[:,0]==1)])+len(y[(y.iloc[:,0]==0)]))\n",
    "    gamma = TP/(TP+FN)\n",
    "    if beta-alfa==0:\n",
    "        gamma_cr = float('inf')\n",
    "        n_cr = float('inf')\n",
    "    else:\n",
    "        gamma_cr = ((beta-alfa)**-1)*((1-alfa)*gamma-(1-beta)*n)\n",
    "        n_cr = ((beta-alfa)**-1)*((beta*n)-(alfa*gamma))\n",
    "        \n",
    "    pi_cr = (c*beta)+((1-c)*alfa)\n",
    "    ##metrics\n",
    "    ACC_cr = (pi_cr*gamma_cr) + ((1-pi_cr)*(1-n_cr))\n",
    "    bacc_cr = (1 + (gamma_cr - n_cr))/2\n",
    "    f_cr = (2*pi_cr*gamma_cr)/(pi_cr+theta)\n",
    "    mcc_cr = (pi_cr*(1-pi_cr)/theta*(1-theta))*(gamma_cr-n_cr)\n",
    "    \n",
    "    auc_r = metrics.auc(fpr, tpr)\n",
    "    auc_cr = (auc_r-(1-(beta-alfa)))/(beta-alfa)\n",
    "    alfa = sum(results_partial[\"pred\"])/results_partial.shape[0]\n",
    "    \n",
    "    metrics_df =[[auc_r,auc_cr,ACC_cr,bacc_cr,f_cr,mcc_cr,alfa]]\n",
    "    return(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68147ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for logistic regression model with optimal threshold\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6988c03",
   "metadata": {},
   "source": [
    "# threshold unweighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0db0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = \"D:/REPO_GITHUB/ALUMINUM_GENES_CLASSIFICATION/RESULTS/UNWEIGHTED/out_pred_LAB_PROP_JJG.csv\"\n",
    "#filename = \"/users/ccsosaa/pecanpy/BIG_COMP_W.emb\"\n",
    "data = pd.read_csv(filename,index_col=0)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8830bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prob_LP'] =data['prob_LP'].fillna(0)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18da6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for logistic regression model with optimal threshold\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot\n",
    "fpr, tpr, thresholds = roc_curve(data[\"1\"], data[\"prob_LP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d5037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "pyplot.plot(fpr, tpr, marker='.', label='Label propagation')\n",
    "pyplot.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab769b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data[\"pred_LP\"])):\n",
    "    if data[\"prob_LP\"][i] > thresholds[ix]:\n",
    "        data[\"prob_LP\"][i] = 1\n",
    "    else:\n",
    "        data[\"prob_LP\"][i] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c3ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"1\"]\n",
    "y = y.to_frame()\n",
    "y_pred = data[\"pred_LP\"]\n",
    "y_pred = y_pred.to_frame()\n",
    "fixed_LP = fixed_metrics(y,y_pred)\n",
    "print(\"AUC\",\"AUCcr\",\"ACCURACY\",\"B_ACCURACY\",\"F\",\"MCC\",\"ALPHA\")\n",
    "print(fixed_LP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192363c9",
   "metadata": {},
   "source": [
    "### precision - recall label propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aaf284",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y,data[\"prob_LP\"])\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
    "# plot the roc curve for the model\n",
    "no_skill = len(data[\"1\"][data[\"1\"]==1]) / len(data[\"1\"])\n",
    "pyplot.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\n",
    "pyplot.plot(recall, precision, marker='.', label='Label propagation')\n",
    "pyplot.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb60027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"pred_LP_PR\"] = data[\"pred_LP\"] #This works. This will create a new column with None type\n",
    "\n",
    "for i in range(len(data[\"pred_LP_PR\"])):\n",
    "    if data[\"prob_LP\"][i] > thresholds[ix]:\n",
    "        data[\"pred_LP_PR\"][i] = 1\n",
    "    else:\n",
    "        data[\"pred_LP_PR\"][i] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33934669",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"1\"]\n",
    "y = y.to_frame()\n",
    "y_pred = data[\"pred_LP_PR\"]\n",
    "y_pred = y_pred.to_frame()\n",
    "fixed_LP = fixed_metrics(y,y_pred)\n",
    "print(\"AUC\",\"AUCcr\",\"ACCURACY\",\"B_ACCURACY\",\"F\",\"MCC\",\"ALPHA\")\n",
    "print(fixed_LP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbcd4b1",
   "metadata": {},
   "source": [
    "# SAVING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34940808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data[[\"1\",\"prob_LP\",\"pred_LP\",\"pred_LP_PR\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaae3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"D:/REPO_GITHUB/ALUMINUM_GENES_CLASSIFICATION/RESULTS/UNWEIGHTED/out_pred_LP_JJG.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ccce3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea78bca6",
   "metadata": {},
   "source": [
    "# threshold weighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8f332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = \"D:/REPO_GITHUB/ALUMINUM_GENES_CLASSIFICATION/RESULTS/WEIGHTED/out_pred_LAB_PROP_JJG.csv\"\n",
    "#filename = \"/users/ccsosaa/pecanpy/BIG_COMP_W.emb\"\n",
    "data = pd.read_csv(filename,index_col=0)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8870e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prob_LP'] =data['prob_LP'].fillna(0)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for logistic regression model with optimal threshold\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot\n",
    "fpr, tpr, thresholds = roc_curve(data[\"1\"], data[\"prob_LP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357863ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "pyplot.plot(fpr, tpr, marker='.', label='Label propagation')\n",
    "pyplot.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b943bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data[\"pred_LP\"])):\n",
    "    if data[\"prob_LP\"][i] > thresholds[ix]:\n",
    "        data[\"prob_LP\"][i] = 1\n",
    "    else:\n",
    "        data[\"prob_LP\"][i] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff475bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"1\"]\n",
    "y = y.to_frame()\n",
    "y_pred = data[\"pred_LP\"]\n",
    "y_pred = y_pred.to_frame()\n",
    "fixed_LP = fixed_metrics(y,y_pred)\n",
    "print(\"AUC\",\"AUCcr\",\"ACCURACY\",\"B_ACCURACY\",\"F\",\"MCC\",\"ALPHA\")\n",
    "print(fixed_LP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16211b44",
   "metadata": {},
   "source": [
    "### precision - recall label propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c9ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y,data[\"prob_LP\"])\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
    "# plot the roc curve for the model\n",
    "no_skill = len(data[\"1\"][data[\"1\"]==1]) / len(data[\"1\"])\n",
    "pyplot.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\n",
    "pyplot.plot(recall, precision, marker='.', label='Label propagation')\n",
    "pyplot.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"pred_LP_PR\"] = data[\"pred_LP\"] #This works. This will create a new column with None type\n",
    "\n",
    "for i in range(len(data[\"pred_LP_PR\"])):\n",
    "    if data[\"prob_LP\"][i] > thresholds[ix]:\n",
    "        data[\"pred_LP_PR\"][i] = 1\n",
    "    else:\n",
    "        data[\"pred_LP_PR\"][i] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba78fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"1\"]\n",
    "y = y.to_frame()\n",
    "y_pred = data[\"pred_LP_PR\"]\n",
    "y_pred = y_pred.to_frame()\n",
    "fixed_LP = fixed_metrics(y,y_pred)\n",
    "print(\"AUC\",\"AUCcr\",\"ACCURACY\",\"B_ACCURACY\",\"F\",\"MCC\",\"ALPHA\")\n",
    "print(fixed_LP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a20a879",
   "metadata": {},
   "source": [
    "# SAVING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d1fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data[[\"1\",\"prob_LP\",\"pred_LP\",\"pred_LP_PR\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08794de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"D:/REPO_GITHUB/ALUMINUM_GENES_CLASSIFICATION/RESULTS/WEIGHTED/out_pred_LP_JJG.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
